https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL

CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name    -- (Note: TEMPORARY available in Hive 0.14.0 and later)
  [(col_name data_type [COMMENT col_comment], ... [constraint_specification])]
  [COMMENT table_comment]
  [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]
  [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]
  [SKEWED BY (col_name, col_name, ...)                  -- (Note: Available in Hive 0.10.0 and later)]
     ON ((col_value, col_value, ...), (col_value, col_value, ...), ...)
     [STORED AS DIRECTORIES]
  [
   [ROW FORMAT row_format] 
   [STORED AS file_format]
     | STORED BY 'storage.handler.class.name' [WITH SERDEPROPERTIES (...)]  -- (Note: Available in Hive 0.6.0 and later)
  ]
  [LOCATION hdfs_path]
  [TBLPROPERTIES (property_name=property_value, ...)]   -- (Note: Available in Hive 0.6.0 and later)
  [AS select_statement];   -- (Note: Available in Hive 0.5.0 and later; not supported for external tables)
 
CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name
  LIKE existing_table_or_view_name
  [LOCATION hdfs_path];
 
data_type
  : primitive_type
  | array_type
  | map_type
  | struct_type
  | union_type  -- (Note: Available in Hive 0.7.0 and later)
 
primitive_type
  : TINYINT
  | SMALLINT
  | INT
  | BIGINT
  | BOOLEAN
  | FLOAT
  | DOUBLE
  | DOUBLE PRECISION -- (Note: Available in Hive 2.2.0 and later)
  | STRING
  | BINARY      -- (Note: Available in Hive 0.8.0 and later)
  | TIMESTAMP   -- (Note: Available in Hive 0.8.0 and later)
  | DECIMAL     -- (Note: Available in Hive 0.11.0 and later)
  | DECIMAL(precision, scale)  -- (Note: Available in Hive 0.13.0 and later)
  | DATE        -- (Note: Available in Hive 0.12.0 and later)
  | VARCHAR     -- (Note: Available in Hive 0.12.0 and later)
  | CHAR        -- (Note: Available in Hive 0.13.0 and later)
 
array_type
  : ARRAY < data_type >
 
map_type
  : MAP < primitive_type, data_type >
 
struct_type
  : STRUCT < col_name : data_type [COMMENT col_comment], ...>
 
union_type
   : UNIONTYPE < data_type, data_type, ... >  -- (Note: Available in Hive 0.7.0 and later)
 
row_format
  : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]
        [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]
        [NULL DEFINED AS char]   -- (Note: Available in Hive 0.13 and later)
  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]
 
file_format:
  : SEQUENCEFILE
  | TEXTFILE    -- (Default, depending on hive.default.fileformat configuration)
  | RCFILE      -- (Note: Available in Hive 0.6.0 and later)
  | ORC         -- (Note: Available in Hive 0.11.0 and later)
  | PARQUET     -- (Note: Available in Hive 0.13.0 and later)
  | AVRO        -- (Note: Available in Hive 0.14.0 and later)
  | JSONFILE    -- (Note: Available in Hive 4.0.0 and later)
  | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname
 
constraint_specification:
  : [, PRIMARY KEY (col_name, ...) DISABLE NOVALIDATE ]
    [, CONSTRAINT constraint_name FOREIGN KEY (col_name, ...) REFERENCES table_name(col_name, ...) DISABLE NOVALIDATE 

https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF
SHOW FUNCTIONS;
DESCRIBE FUNCTION <function_name>;
DESCRIBE FUNCTION EXTENDED <function_name>;

--Built-in Operators
Operators Precedences
-A, A IS [NOT] (NULL|TRUE|FALSE), A ^ B, A * B, A + B, A || B, A & B, A | B

Relational Operators
A = B, A == B, 
A <=> B
Note: 
Returns same result with EQUAL(=) operator for non-null operands, but returns TRUE if both are NULL, FALSE if one of the them is NULL.,
A <> B 
Note :
NULL if A or B is NULL, TRUE if expression A is NOT equal to expression B, otherwise FALSE.,
A != B,
A < B,
A <= B,
A > B,
A >= B,
A [NOT] BETWEEN B AND C,
A IS NULL,
A IS NOT NULL,
A IS [NOT] (TRUE|FALSE),
A [NOT] LIKE B,
A RLIKE B,
A REGEXP B

Arithmetic Operators
A + B, A - B,A * B, A / B, A DIV B, A % B, A & B, A | B, A ^ B, ~A

Logical Operators
A AND B, A OR B, NOT A, ! A, A IN (val1, val2, ...), A NOT IN (val1, val2, ...), [NOT] EXISTS (subquery)

String Operators
A || B

Complex Type Constructors
Operators on Complex Types
A[n]
M[key]
S.x


--Built-in Functions
round(DOUBLE a), round(DOUBLE a, INT d), bround(DOUBLE a),bround(DOUBLE a, INT d)
floor(DOUBLE a)
ceil(DOUBLE a), ceiling(DOUBLE a)
rand(), rand(INT seed)

--Built-in Aggregate Functions (UDAF)
count(*), count(expr), count(DISTINCT expr[, expr...])
sum(col), sum(DISTINCT col)
avg(col), avg(DISTINCT col)


--Built-in Table-Generating Functions (UDTF)
--GROUPing and SORTing on f(column)
--UDF internals
--Creating Custom UDFs


https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML
--Hive Data Manipulation Language
Loading files into tables
Hive does not do any transformation while loading data into tables. Load operations 
are currently pure copy/move operations that move datafiles into locations corresponding 
to Hive tables.

LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]
 
LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)] [INPUTFORMAT 'inputformat' SERDE 'serde'] (3.0 or later)

example:

CREATE TABLE tab1 (col1 int, col2 int) PARTITIONED BY (col3 int) STORED AS ORC;
LOAD DATA LOCAL INPATH 'filepath' INTO TABLE tab1;

--Inserting data into Hive Tables from queries
*INSERT OVERWRITE will overwrite any existing data in the table or partition

*INSERT INTO will append to the table or partition, keeping the existing data intact. 

*In the dynamic partition inserts, users can give partial partition specifications, 
which means just specifying the list of partition column names in the PARTITION clause. 
The column values are optional. If a partition column value is given, we call this a 
static partition, otherwise it is a dynamic partition. Each dynamic partition column 
has a corresponding input column from the select statement. This means that the dynamic 
partition creation is determined by the value of the input column. The dynamic partition 
columns must be specified last among the columns in the SELECT statement and in the same 
order in which they appear in the PARTITION() clause.

*check for partition properties:

set hive.exec.dynamic.partition;
set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode;
set hive.exec.dynamic.partition.mode=nonstrict;
set hive.exec.max.dynamic.partitions.pernode;
set hive.exec.max.dynamic.partitions.pernode=100;
set hive.exec.max.dynamic.partitions;
set hive.exec.max.dynamic.partitions=1000;
set hive.exec.max.created.files;
set hive.exec.max.created.files=100000;
set hive.error.on.empty.partition;
set hive.error.on.empty.partition=false;


Standard syntax:
INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...) [IF NOT EXISTS]] select_statement1 FROM from_statement;
INSERT INTO TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1 FROM from_statement;
 
Hive extension (multiple inserts):
FROM from_statement
INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...) [IF NOT EXISTS]] select_statement1
[INSERT OVERWRITE TABLE tablename2 [PARTITION ... [IF NOT EXISTS]] select_statement2]
[INSERT INTO TABLE tablename2 [PARTITION ...] select_statement2] ...;
FROM from_statement
INSERT INTO TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1
[INSERT INTO TABLE tablename2 [PARTITION ...] select_statement2]
[INSERT OVERWRITE TABLE tablename2 [PARTITION ... [IF NOT EXISTS]] select_statement2] ...;
 
Hive extension (dynamic partition inserts):
INSERT OVERWRITE TABLE tablename PARTITION (partcol1[=val1], partcol2[=val2] ...) select_statement FROM from_statement;
INSERT INTO TABLE tablename PARTITION (partcol1[=val1], partcol2[=val2] ...) select_statement FROM from_statement;

--Writing data into the filesystem from queries
Standard syntax:
INSERT OVERWRITE [LOCAL] DIRECTORY directory1
  [ROW FORMAT row_format] [STORED AS file_format] (Note: Only available starting with Hive 0.11.0)
  SELECT ... FROM ...
 
Hive extension (multiple inserts):
FROM from_statement
INSERT OVERWRITE [LOCAL] DIRECTORY directory1 select_statement1
[INSERT OVERWRITE [LOCAL] DIRECTORY directory2 select_statement2] ...
 
  
row_format
  : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]
        [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]
        [NULL DEFINED AS char] (Note: Only available starting with Hive 0.13)

--Inserting values into tables from SQL
Standard Syntax:
INSERT INTO TABLE tablename [PARTITION (partcol1[=val1], partcol2[=val2] ...)] VALUES values_row [, values_row ...]
  
Where values_row is:
( value [, value ...] )
where a value is either null or any valid SQL literal


--Update(0.14 onwards)
Standard Syntax:
UPDATE tablename SET column = value [, column = value ...] [WHERE expression]

--Delete(0.14 onwards)
Standard Syntax:
DELETE FROM tablename [WHERE expression]
--Merge(2.2 onwards)
Standard Syntax:
MERGE INTO <target table> AS T USING <source expression/table> AS S
ON <boolean expression1>
WHEN MATCHED [AND <boolean expression2>] THEN UPDATE SET <set clause list>
WHEN MATCHED [AND <boolean expression3>] THEN DELETE
WHEN NOT MATCHED [AND <boolean expression4>] THEN INSERT VALUES<value list>

https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ImportExport

The EXPORT command exports the data of a table or partition, along with the metadata, into a specified output location. This output location can then be moved over to a different Hadoop or Hive instance and imported from there with the IMPORT command.

When exporting a partitioned table, the original data may be located in different HDFS locations. The ability to export/import a subset of the partition is also supported.

Exported metadata is stored in the target directory, and data files are stored in subdirectories.

The EXPORT and IMPORT commands work independently of the source and target metastore DBMS used; for example, they can be used between Derby and MySQL databases.

IMPORT will create target table/partition if it does not exist.  All the table 
properties/parameters will be that of table that was used in EXPORT to generate 
the archive.  If target exists, checks are performed that it has appropriate schema, 
Input/OutputFormat, etc.  If target table exists and is not partitioned, it must be empty.
If target table exists and is partitioned, partitions being imported must not exist in 
the table.  

Export Syntax:
EXPORT TABLE tablename [PARTITION (part_column="value"[, ...])]
  TO 'export_target_path' [ FOR replication('eventid') ]

Import Syntax:  
IMPORT [[EXTERNAL] TABLE new_or_original_tablename [PARTITION (part_column="value"[, ...])]]
  FROM 'source_path'
  [LOCATION 'import_target_path']
  
Simple export and import:
export table department to 'hdfs_exports_location/department';
import from 'hdfs_exports_location/department';

Rename table on import:
export table department to 'hdfs_exports_location/department';
import table imported_dept from 'hdfs_exports_location/department';

Export partition and import:
export table employee partition (emp_country="in", emp_state="ka") to 'hdfs_exports_location/employee';
import from 'hdfs_exports_location/employee';

Export table and import partition:
export table employee to 'hdfs_exports_location/employee';
import table employee partition (emp_country="us", emp_state="tn") from 'hdfs_exports_location/employee';

Specify the import location:
export table department to 'hdfs_exports_location/department';
import table department from 'hdfs_exports_location/department' 
       location 'import_target_location/department';

Import as an external table:
export table department to 'hdfs_exports_location/department';
import external table department from 'hdfs_exports_location/department';

https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Explain
Hive provides an EXPLAIN command that shows the execution plan for a query. 
The syntax for this statement is as follows:	   

EXPLAIN Syntax:
EXPLAIN [EXTENDED|DEPENDENCY|AUTHORIZATION|LOCKS|VECTORIZATION] query

https://cwiki.apache.org/confluence/display/Hive/StatsDev

ANALYZE TABLE [db_name.]tablename [PARTITION(partcol1[=val1], partcol2[=val2], ...)]  -- (Note: Fully support qualified table name since Hive 1.2.0, see HIVE-10007.)
  COMPUTE STATISTICS 
  [FOR COLUMNS]          -- (Note: Hive 0.10.0 and later.)
  [CACHE METADATA]       -- (Note: Hive 2.1.0 and later.)
  [NOSCAN];
  
Suppose table Table1 has 4 partitions with the following specs:

Partition1: (ds='2008-04-08', hr=11)
Partition2: (ds='2008-04-08', hr=12)
Partition3: (ds='2008-04-09', hr=11)
Partition4: (ds='2008-04-09', hr=12)

ANALYZE TABLE Table1 PARTITION(ds='2008-04-09', hr=11) COMPUTE STATISTICS;
ANALYZE TABLE Table1 PARTITION(ds='2008-04-09', hr=11) COMPUTE STATISTICS FOR COLUMNS;
ANALYZE TABLE Table1 PARTITION(ds='2008-04-09', hr) COMPUTE STATISTICS;
ANALYZE TABLE Table1 PARTITION(ds='2008-04-09', hr) COMPUTE STATISTICS FOR COLUMNS;
ANALYZE TABLE Table1 PARTITION(ds, hr) COMPUTE STATISTICS;
ANALYZE TABLE Table1 PARTITION(ds, hr) COMPUTE STATISTICS FOR COLUMNS;
ANALYZE TABLE Table1 COMPUTE STATISTICS;
ANALYZE TABLE Table1 COMPUTE STATISTICS FOR COLUMNS;


https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Indexing
*********************************************************************************************
***********************Hadoop-The Definitive Guide*******************************************
*********************************************************************************************
hive -e 'SELECT * FROM dummy'
hive -f hive_script.hql
hive -S -e 'SELECT * FROM dummy'

SET hive.execution.engine=tez;

--Hive Services
cli
hiveserver2
beeline
hwi(hive web interface)
jar
metastore

--Hive clients
Thrift Client
JDBC driver
ODBC driver

--Schema on Read Versus Schema on Write
--Managed Tables and External Tables
--Partitions and Buckets
--Multitable insert
--
CREATE FUNCTION strip AS 'com.hadoopbook.hive.Strip'
USING JAR '/path/to/hive-examples.jar';
DROP FUNCTION strip;

ADD JAR /path/to/hive-examples.jar;
CREATE TEMPORARY FUNCTION strip AS 'com.hadoopbook.hive.Strip';

